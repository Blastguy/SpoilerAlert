{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess(val):\n",
    "    nltk.download('stopwords')\n",
    "    stop = stopwords.words('english')\n",
    "    input_txt = {'review_text' : [val]}\n",
    "    val = pd.DataFrame(input_txt, columns=['review_text'])\n",
    "\n",
    "    val['review_text'] = val['review_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    \n",
    "    st = PorterStemmer()\n",
    "    val['review_text'] = val['review_text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "    \n",
    "    regex = r'\\d+'\n",
    "    val['review_text'] = val['review_text'].apply(lambda x:\" \".join(re.sub(regex, 'numbers', word) for word in x.split()))\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    xtrain = pickle.load(open('train.pkl','rb'))\n",
    "    vectorizer.fit_transform(xtrain)\n",
    "    val = vectorizer.transform(list(val['review_text']))\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/arvind_anand1123/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "s = \"THIS REVIEW IS FAKE NOOSE\"\n",
    "pred = preprocess(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load(open('model.pkl','rb'))\n",
    "print(model.predict(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
